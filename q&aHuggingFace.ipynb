{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "## Fine-Tuning T5 for Question Answering using HuggingFace Transformers\n",
    "To build a model that can generate answers based on given context and questions , we focused on finetuning a hugging face model T5 for creating a q&a context chatbot\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic and code reference : https://analyticsindiamag.com/guide-to-question-answering-system-with-t5-transformer/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About T5 transformer Hugging Face\n",
    "\n",
    "About the T5 transformer-\n",
    "The T5 model is based on the Transformer architecture, which is a type of neural network that is designed to process sequential input data efficiently. It consists of an encoder and a decoder, which are both made up of a series of interconnected \"layers.\"\n",
    "\n",
    "Each layer in the encoder and decoder is made up of a series of \"attention\" mechanisms and \"feedforward\" networks. The attention mechanisms allow the model to focus on different parts of the input sequence at different times, while the feedforward networks transform the input data using a series of weights and biases.\n",
    "\n",
    "The T5 model also uses something called \"self-attention,\" which allows each element in the input sequence to attend to all of the other elements in the sequence. This enables the model to capture relationships between words and phrases in the input data, which is important for many NLP tasks.\n",
    "\n",
    "In addition to the encoder and decoder, the T5 model also includes something called a \"language model head,\" which is used to predict the next word in a sequence given the previous words. This is important for tasks like translation and text generation, where the model needs to generate coherent and natural-sounding output.\n",
    "\n",
    "Overall, the T5 model is a very large and complex neural network, but it is designed to be highly efficient and effective at processing sequential data. It has been trained on a massive dataset of text and can perform a wide range of NLP tasks with state-of-the-art accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-01-13T07:11:04.997844Z",
     "iopub.status.busy": "2023-01-13T07:11:04.997370Z",
     "iopub.status.idle": "2023-01-13T07:11:14.578297Z",
     "shell.execute_reply": "2023-01-13T07:11:14.577279Z",
     "shell.execute_reply.started": "2023-01-13T07:11:04.997763Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import T5Tokenizer\n",
    "from transformers import T5ForConditionalGeneration, AdamW\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "pl.seed_everything(100)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T07:11:14.580953Z",
     "iopub.status.busy": "2023-01-13T07:11:14.580247Z",
     "iopub.status.idle": "2023-01-13T07:11:14.804856Z",
     "shell.execute_reply": "2023-01-13T07:11:14.803699Z",
     "shell.execute_reply.started": "2023-01-13T07:11:14.580922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'context', 'question', 'id', 'answer_start', 'text'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:/GeorgeBrownSubjects/DeepLearningMaths/Project2/Data/SQuAD_csv.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T07:11:14.807805Z",
     "iopub.status.busy": "2023-01-13T07:11:14.806689Z",
     "iopub.status.idle": "2023-01-13T07:11:14.823561Z",
     "shell.execute_reply": "2023-01-13T07:11:14.822377Z",
     "shell.execute_reply.started": "2023-01-13T07:11:14.807760Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[['context','question', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T07:11:14.829190Z",
     "iopub.status.busy": "2023-01-13T07:11:14.828899Z",
     "iopub.status.idle": "2023-01-13T07:11:14.835697Z",
     "shell.execute_reply": "2023-01-13T07:11:14.834325Z",
     "shell.execute_reply.started": "2023-01-13T07:11:14.829163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records:  86821\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of records: \", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T07:11:14.839181Z",
     "iopub.status.busy": "2023-01-13T07:11:14.838285Z",
     "iopub.status.idle": "2023-01-13T07:11:14.907631Z",
     "shell.execute_reply": "2023-01-13T07:11:14.906705Z",
     "shell.execute_reply.started": "2023-01-13T07:11:14.839140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beyoncé giselle knowles-carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>when did beyonce start becoming popular?</td>\n",
       "      <td>in the late 1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beyoncé giselle knowles-carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>what areas did beyonce compete in when she was...</td>\n",
       "      <td>singing and dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beyoncé giselle knowles-carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>when did beyonce leave destiny's child and bec...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beyoncé giselle knowles-carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>in what city and state did beyonce  grow up?</td>\n",
       "      <td>houston, texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beyoncé giselle knowles-carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>in which decade did beyonce become famous?</td>\n",
       "      <td>late 1990s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  beyoncé giselle knowles-carter (/biːˈjɒnseɪ/ b...   \n",
       "1  beyoncé giselle knowles-carter (/biːˈjɒnseɪ/ b...   \n",
       "2  beyoncé giselle knowles-carter (/biːˈjɒnseɪ/ b...   \n",
       "3  beyoncé giselle knowles-carter (/biːˈjɒnseɪ/ b...   \n",
       "4  beyoncé giselle knowles-carter (/biːˈjɒnseɪ/ b...   \n",
       "\n",
       "                                            question                 text  \n",
       "0           when did beyonce start becoming popular?    in the late 1990s  \n",
       "1  what areas did beyonce compete in when she was...  singing and dancing  \n",
       "2  when did beyonce leave destiny's child and bec...                 2003  \n",
       "3      in what city and state did beyonce  grow up?        houston, texas  \n",
       "4         in which decade did beyonce become famous?           late 1990s  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"context\"] = df[\"context\"].str.lower()\n",
    "df[\"question\"] = df[\"question\"].str.lower()\n",
    "df[\"text\"] = df[\"text\"].str.lower()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T07:11:14.909596Z",
     "iopub.status.busy": "2023-01-13T07:11:14.909254Z",
     "iopub.status.idle": "2023-01-13T07:11:15.018148Z",
     "shell.execute_reply": "2023-01-13T07:11:15.016536Z",
     "shell.execute_reply.started": "2023-01-13T07:11:14.909560Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "INPUT_MAX_LEN = 512 # Input length\n",
    "OUT_MAX_LEN = 128 # Output Length\n",
    "TRAIN_BATCH_SIZE = 8 # Training Batch Size\n",
    "VALID_BATCH_SIZE = 2 # Validation Batch Size\n",
    "EPOCHS = 5 # Number of Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T07:11:15.020855Z",
     "iopub.status.busy": "2023-01-13T07:11:15.020027Z",
     "iopub.status.idle": "2023-01-13T07:11:15.924492Z",
     "shell.execute_reply": "2023-01-13T07:11:15.923613Z",
     "shell.execute_reply.started": "2023-01-13T07:11:15.020808Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"t5-base\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME, model_max_length= INPUT_MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T07:11:15.926334Z",
     "iopub.status.busy": "2023-01-13T07:11:15.925784Z",
     "iopub.status.idle": "2023-01-13T07:11:15.933885Z",
     "shell.execute_reply": "2023-01-13T07:11:15.931825Z",
     "shell.execute_reply.started": "2023-01-13T07:11:15.926296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eos_token: </s> and id: 1\n",
      "unk_token: <unk> and id: 1\n",
      "pad_token: <pad> and id: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"eos_token: {} and id: {}\".format(tokenizer.eos_token, tokenizer.eos_token_id)) # End of token (eos_token)\n",
    "print(\"unk_token: {} and id: {}\".format(tokenizer.unk_token, tokenizer.eos_token_id)) # Unknown token (unk_token)\n",
    "print(\"pad_token: {} and id: {}\".format(tokenizer.pad_token, tokenizer.eos_token_id)) # Pad token (pad_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T07:11:15.936375Z",
     "iopub.status.busy": "2023-01-13T07:11:15.935392Z",
     "iopub.status.idle": "2023-01-13T07:11:15.948644Z",
     "shell.execute_reply": "2023-01-13T07:11:15.947605Z",
     "shell.execute_reply.started": "2023-01-13T07:11:15.936337Z"
    }
   },
   "outputs": [],
   "source": [
    "class T5Dataset:\n",
    "\n",
    "    def __init__(self, context, question, target):\n",
    "        self.context = context\n",
    "        self.question = question\n",
    "        self.target = target\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_max_len = INPUT_MAX_LEN\n",
    "        self.out_max_len = OUT_MAX_LEN\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.context)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        context = str(self.context[item])\n",
    "        context = \" \".join(context.split())\n",
    "\n",
    "        question = str(self.question[item])\n",
    "        question = \" \".join(question.split())\n",
    "\n",
    "        target = str(self.target[item])\n",
    "        target = \" \".join(target.split())\n",
    "        \n",
    "        \n",
    "        inputs_encoding = self.tokenizer(\n",
    "            context,\n",
    "            question,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.input_max_len,\n",
    "            padding = 'max_length',\n",
    "            truncation='only_first',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "\n",
    "        output_encoding = self.tokenizer(\n",
    "            target,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.out_max_len,\n",
    "            padding = 'max_length',\n",
    "            truncation= True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "\n",
    "        inputs_ids = inputs_encoding[\"input_ids\"].flatten()\n",
    "        attention_mask = inputs_encoding[\"attention_mask\"].flatten()\n",
    "        labels = output_encoding[\"input_ids\"]\n",
    "\n",
    "        labels[labels == 0] = -100  # As per T5 Documentation\n",
    "\n",
    "        labels = labels.flatten()\n",
    "\n",
    "        out = {\n",
    "            \"context\": context,\n",
    "            \"question\": question,\n",
    "            \"answer\": target,\n",
    "            \"inputs_ids\": inputs_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"targets\": labels\n",
    "        }\n",
    "\n",
    "\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T07:11:15.952864Z",
     "iopub.status.busy": "2023-01-13T07:11:15.952390Z",
     "iopub.status.idle": "2023-01-13T07:11:15.962462Z",
     "shell.execute_reply": "2023-01-13T07:11:15.961690Z",
     "shell.execute_reply.started": "2023-01-13T07:11:15.952838Z"
    }
   },
   "outputs": [],
   "source": [
    "class T5DatasetModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, df_train, df_valid):\n",
    "        super().__init__()\n",
    "        self.df_train = df_train\n",
    "        self.df_valid = df_valid\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_max_len = INPUT_MAX_LEN\n",
    "        self.out_max_len = OUT_MAX_LEN\n",
    "\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        self.train_dataset = T5Dataset(\n",
    "        context=self.df_train.context.values,\n",
    "        question=self.df_train.question.values,\n",
    "        target=self.df_train.text.values\n",
    "        )\n",
    "\n",
    "        self.valid_dataset = T5Dataset(\n",
    "        context=self.df_valid.context.values,\n",
    "        question=self.df_valid.question.values,\n",
    "        target=self.df_valid.text.values\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "         self.train_dataset,\n",
    "         batch_size= TRAIN_BATCH_SIZE,\n",
    "         shuffle=True, \n",
    "         num_workers=4\n",
    "        )\n",
    "\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "         self.valid_dataset,\n",
    "         batch_size= VALID_BATCH_SIZE,\n",
    "         num_workers=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T07:11:15.964587Z",
     "iopub.status.busy": "2023-01-13T07:11:15.963712Z",
     "iopub.status.idle": "2023-01-13T07:11:15.974798Z",
     "shell.execute_reply": "2023-01-13T07:11:15.974048Z",
     "shell.execute_reply.started": "2023-01-13T07:11:15.964550Z"
    }
   },
   "outputs": [],
   "source": [
    "class T5Model(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict=True)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "\n",
    "        output = self.model(\n",
    "            input_ids=input_ids, \n",
    "            attention_mask=attention_mask, \n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        return output.loss, output.logits\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        input_ids = batch[\"inputs_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels= batch[\"targets\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "\n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"inputs_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels= batch[\"targets\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T07:11:15.977118Z",
     "iopub.status.busy": "2023-01-13T07:11:15.976017Z",
     "iopub.status.idle": "2023-01-13T09:04:27.681351Z",
     "shell.execute_reply": "2023-01-13T09:04:27.680155Z",
     "shell.execute_reply.started": "2023-01-13T07:11:15.977062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b437d7edf2c041e6b849bb422897c09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/850M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851c33aa6c4c4212846001f24b2dbcf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run():\n",
    "    \n",
    "    df_train, df_valid = train_test_split(\n",
    "        df[0:10000], test_size=0.2, random_state=101\n",
    "    )\n",
    "    \n",
    "    df_train = df_train.fillna(\"none\")\n",
    "    df_valid = df_valid.fillna(\"none\")\n",
    "    \n",
    "    df_train['context'] = df_train['context'].apply(lambda x: \" \".join(x.split()))\n",
    "    df_valid['context'] = df_valid['context'].apply(lambda x: \" \".join(x.split()))\n",
    "    \n",
    "    df_train['text'] = df_train['text'].apply(lambda x: \" \".join(x.split()))\n",
    "    df_valid['text'] = df_valid['text'].apply(lambda x: \" \".join(x.split()))\n",
    "    \n",
    "    df_train['question'] = df_train['question'].apply(lambda x: \" \".join(x.split()))\n",
    "    df_valid['question'] = df_valid['question'].apply(lambda x: \" \".join(x.split()))\n",
    "\n",
    "   \n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_valid = df_valid.reset_index(drop=True)\n",
    "    \n",
    "    dataModule = T5DatasetModule(df_train, df_valid)\n",
    "    dataModule.setup()\n",
    "\n",
    "    device = DEVICE\n",
    "    models = T5Model()\n",
    "    models.to(device)\n",
    "\n",
    "    checkpoint_callback  = ModelCheckpoint(\n",
    "        dirpath=\"/kaggle/working\",\n",
    "        filename=\"best_checkpoint\",\n",
    "        save_top_k=2,\n",
    "        verbose=True,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\"\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        callbacks = checkpoint_callback,\n",
    "        max_epochs= EPOCHS,\n",
    "        gpus=1,\n",
    "        accelerator=\"gpu\"\n",
    "    )\n",
    "\n",
    "    trainer.fit(models, dataModule)\n",
    "\n",
    "run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prediction\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T09:04:27.683793Z",
     "iopub.status.busy": "2023-01-13T09:04:27.683364Z",
     "iopub.status.idle": "2023-01-13T09:04:37.161458Z",
     "shell.execute_reply": "2023-01-13T09:04:37.160459Z",
     "shell.execute_reply.started": "2023-01-13T09:04:27.683730Z"
    }
   },
   "outputs": [],
   "source": [
    "train_model = T5Model.load_from_checkpoint(\"/kaggle/working/best_checkpoint-v1.ckpt\")\n",
    "\n",
    "train_model.freeze()\n",
    "\n",
    "def generate_question(context, question):\n",
    "\n",
    "    inputs_encoding =  tokenizer(\n",
    "        context,\n",
    "        question,\n",
    "        add_special_tokens=True,\n",
    "        max_length= INPUT_MAX_LEN,\n",
    "        padding = 'max_length',\n",
    "        truncation='only_first',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "    \n",
    "    generate_ids = train_model.model.generate(\n",
    "        input_ids = inputs_encoding[\"input_ids\"],\n",
    "        attention_mask = inputs_encoding[\"attention_mask\"],\n",
    "        max_length = INPUT_MAX_LEN,\n",
    "        num_beams = 4,\n",
    "        num_return_sequences = 1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True,\n",
    "        )\n",
    "\n",
    "    preds = [\n",
    "        tokenizer.decode(gen_id,\n",
    "        skip_special_tokens=True, \n",
    "        clean_up_tokenization_spaces=True)\n",
    "        for gen_id in generate_ids\n",
    "    ]\n",
    "\n",
    "    return \"\".join(preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T09:04:37.163505Z",
     "iopub.status.busy": "2023-01-13T09:04:37.163078Z",
     "iopub.status.idle": "2023-01-13T09:04:39.658565Z",
     "shell.execute_reply": "2023-01-13T09:04:39.657409Z",
     "shell.execute_reply.started": "2023-01-13T09:04:37.163465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credit card fraud detection\n"
     ]
    }
   ],
   "source": [
    "context = \"Clustering groups of similar cases, for example, \\\n",
    "can find similar patients, or can be used for customer segmentation in the \\\n",
    "banking field. Association technique is used for finding items or events that \\\n",
    "often co-occur, for example, grocery items that are usually bought together\\\n",
    "by a particular customer. Anomaly detection is used to discover abnormal \\\n",
    "and unusual cases, for example, it is used for credit card fraud detection.\"\n",
    "\n",
    "que = \"what is the example of Anomaly detection?\"\n",
    "\n",
    "print(generate_question(context, que))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T09:06:58.925465Z",
     "iopub.status.busy": "2023-01-13T09:06:58.925033Z",
     "iopub.status.idle": "2023-01-13T09:07:01.788435Z",
     "shell.execute_reply": "2023-01-13T09:07:01.787450Z",
     "shell.execute_reply.started": "2023-01-13T09:06:58.925428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when your target is categorical\n"
     ]
    }
   ],
   "source": [
    "context = \"Classification is used when your target is categorical, while regression is used when your target variable\\\n",
    "is continuous. Both classification and regression belong to the category of supervised machine learning algorithms.\"\n",
    "\n",
    "que = \"When is classification used?\"\n",
    "\n",
    "print(generate_question(context, que))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Results\n",
    "\n",
    "Our model is successfully able to answer to the given questions based on the feeded context"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Resources\n",
    "\n",
    "Data:https://www.kaggle.com/datasets/rtatman/questionanswer-dataset\n",
    "\n",
    "t5 resource : https://huggingface.co/transformers/v3.0.2/model_doc/t5.html\n",
    "\n",
    "Code and topic reference from this youtube video: https://www.youtube.com/watch?v=r6XY80Z9eSA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
